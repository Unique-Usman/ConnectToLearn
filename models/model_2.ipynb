{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing langchain modules\n",
    "\n",
    "from langchain.document_loaders import UnstructuredExcelLoader\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain import OpenAI, VectorDBQA\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.text_splitter import TokenTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "import tiktoken\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.callbacks     import get_openai_callback\n",
    "#importing the os\n",
    "from PyPDF2 import PdfFileReader\n",
    "import os\n",
    "OPENAI_API_KEY = \"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\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "from langchain.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # Set a really small chunk size, just to show.\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap  = 200,\n",
    "    length_function = len,\n",
    "    add_start_index = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loader = UnstructuredExcelLoader(\n",
    "    \"excel/founders.xlsx\"\n",
    ")\n",
    "\n",
    "docs = loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_chain = ConversationalRetrievalChain.from_llm(llm=ChatOpenAI(), chain_type=\"stuff\",retriever=vectorestore.as_retriever(), memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_chain({\"question\":\"Recommend a professor for Quantum computing\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_chain({\"question\":\"Who is Manoj Kannan\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_chain({\"question\":\"What of Manoj Kannan\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_chain({\"question\":\"Does Manoj Kanan Knows about programming\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_chain({\"question\":\"Can I meet him to learn about C++\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_chain({\"question\":\"Do you know Navjut Kaur\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_chain({\"question\":\"Which professor can I meet for Aeuronautics\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_chain({\"question\":\"Why Srikant\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "def tiktoken_len(text):\n",
    "    token  = tokenizer.encode(\n",
    "        text,\n",
    "        disallowed_special=()\n",
    "    )\n",
    "    return len(token)\n",
    "token_counts = [tiktoken_len(doc.page_content) for doc in all_splits]\n",
    "print(sum(token_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Embed and store the texts\n",
    "#Supplying a persist_directory will stoer the embeddings on disk\n",
    "persist_directory = \"db_founder\"\n",
    "\n",
    "# create the open-source embedding function\n",
    "vectordb = Chroma.from_documents(documents=all_splits,embedding=OpenAIEmbeddings(),\n",
    "        persist_directory=persist_directory)\n",
    "\n",
    "#persist the db to disk\n",
    "vectordb.persist()\n",
    "vectordb = None\n",
    "\n",
    "vectordb = Chroma.from_documents(documents=all_splits,embedding=OpenAIEmbeddings(),\n",
    "        persist_directory=persist_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval = vectordb.as_retriever(search_kwargs={\"k\":2})\n",
    "#docs = retrieval.get_relevant_documents(\"Who is Rucha Joshi\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with get_openai_callback() as cb:\n",
    "        qa_chain = RetrievalQA.from_chain_type(llm=OpenAI(), chain_type=\"stuff\", retriever=retrieval,\n",
    "                return_source_documents=True, verbose=True)\n",
    "        print(qa_chain(\"Robotics\"))\n",
    "total_tokens = cb.total_tokens\n",
    "print(qa_chain.combine_documents_chain.llm_chain.prompt.template)\n",
    "print(total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: db_founder/ (stored 0%)\n",
      "  adding: db_founder/index/ (stored 0%)\n",
      "  adding: db_founder/index/index_metadata_698b7840-3df3-4f8c-9c47-5a73f26a6f61.pkl (deflated 14%)\n",
      "  adding: db_founder/index/uuid_to_id_698b7840-3df3-4f8c-9c47-5a73f26a6f61.pkl (deflated 39%)\n",
      "  adding: db_founder/index/index_698b7840-3df3-4f8c-9c47-5a73f26a6f61.bin (deflated 17%)\n",
      "  adding: db_founder/index/id_to_uuid_698b7840-3df3-4f8c-9c47-5a73f26a6f61.pkl (deflated 35%)\n",
      "  adding: db_founder/chroma-embeddings.parquet (deflated 28%)\n",
      "  adding: db_founder/chroma-collections.parquet (deflated 50%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r db.zip ./db_founder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To cleanup, you can delete the collection\n",
    "vectordb.delete_collection()\n",
    "vectordb.persist()\n",
    "\n",
    "#delete the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf db/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Restarting the runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  db.zip\n",
      "   creating: db/\n",
      "   creating: db/index/\n",
      "  inflating: db/index/id_to_uuid_6cfb6143-f2c4-4043-82da-7f4ed75b6bba.pkl  \n",
      "  inflating: db/index/index_metadata_6cfb6143-f2c4-4043-82da-7f4ed75b6bba.pkl  \n",
      "  inflating: db/index/index_6cfb6143-f2c4-4043-82da-7f4ed75b6bba.bin  \n",
      "  inflating: db/index/uuid_to_id_6cfb6143-f2c4-4043-82da-7f4ed75b6bba.pkl  \n",
      "  inflating: db/chroma-embeddings.parquet  \n",
      "  inflating: db/chroma-collections.parquet  \n",
      "  inflating: db_founder/index/index_metadata_698b7840-3df3-4f8c-9c47-5a73f26a6f61.pkl  \n",
      "  inflating: db_founder/index/uuid_to_id_698b7840-3df3-4f8c-9c47-5a73f26a6f61.pkl  \n",
      "  inflating: db_founder/index/index_698b7840-3df3-4f8c-9c47-5a73f26a6f61.bin  \n",
      "  inflating: db_founder/index/id_to_uuid_698b7840-3df3-4f8c-9c47-5a73f26a6f61.pkl  \n",
      "replace db_founder/chroma-embeddings.parquet? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n"
     ]
    }
   ],
   "source": [
    "!unzip db.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing langchain modules\n",
    "\n",
    "from langchain.document_loaders import UnstructuredExcelLoader\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain import OpenAI, VectorDBQA\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.text_splitter import TokenTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain import OpenAI, LLMChain, PromptTemplate\n",
    "import tiktoken\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "#importing the os\n",
    "\n",
    "from config import OPENAI_API_KEY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = \"db\"\n",
    "\n",
    "# create the open-source embedding function\n",
    "vectordb2 = Chroma(embedding_function=OpenAIEmbeddings(),\n",
    "        persist_directory=persist_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"You are a chatbot having a conversation with a human.\n",
    "\n",
    "Given the following extracted parts of a long document and a question, create a final answer.\n",
    "\n",
    "{context}\n",
    "\n",
    "{chat_history}\n",
    "Human: {human_input}\n",
    "Chatbot:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"human_input\", \"context\"], template=template\n",
    ")\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", input_key=\"human_input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = load_qa_chain(\n",
    "    OpenAI(temperature=0), chain_type=\"stuff\", memory=memory, prompt=prompt,verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Hi\"\n",
    "retrieval = vectordb2.similarity_search(query)\n",
    "chain({\"input_documents\": retrieval, \"human_input\": query}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"I am interested to learn about professor on the Quantom mechanics, who can I meet\"\n",
    "chain({\"input_documents\": retrieval, \"human_input\": query}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query = \"He does not have any experience in quantum mechanics\"\n",
    "chain({\"input_documents\": retrieval, \"human_input\": query}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query = \"Go through the docs which I provided and recommend another professor with Quantum mechanics background\"\n",
    "chain({\"input_documents\": retrieval, \"human_input\": query})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'query': 'Which professor can I meet to learn C++ from and give information about him', 'result': ' You can meet Dr. Srikant Srinivasan to learn C++ from. He is a faculty member at the university.', 'source_documents': [Document(page_content='faculty\\n      \\n    \\n    \\n      Dr. Srikant Srinivasan', metadata={'source': 'excel/database.xlsx'}), Document(page_content='faculty\\n      \\n    \\n    \\n      Dr. Srikant Srinivasan', metadata={'source': 'excel/database.xlsx'}), Document(page_content='faculty\\n      \\n    \\n    \\n      Dr. Srikant Srinivasan', metadata={'source': 'excel/database.xlsx'}), Document(page_content='faculty\\n      \\n    \\n    \\n      Dr. Srikant Srinivasan', metadata={'source': 'excel/database.xlsx'})]}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
