{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing langchain modules\n",
    "\n",
    "from langchain.document_loaders import UnstructuredExcelLoader\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain import OpenAI, VectorDBQA\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.text_splitter import TokenTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "from langchain.document_loaders import TextLoader\n",
    "import tiktoken\n",
    "from langchain.callbacks import get_openai_callback\n",
    "#importing the os\n",
    "\n",
    "from config import OPENAI_API_KEY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the excel files\n",
    "loader = UnstructuredExcelLoader(\n",
    "    \"excel/database.xlsx\"\n",
    ")\n",
    "\n",
    "docs = loader.load()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter_character = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=10000, chunk_overlap=1000\n",
    ")\n",
    "\n",
    " \n",
    "#docs = TextLoader('file.txt').load()\n",
    "#embedding\n",
    "all_splits = text_splitter_character.split_documents(docs)\n",
    "#db = FAISS.from_documents(text_character, OpenAIEmbeddings())\n",
    "# print(type(all_splits))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221639\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "def tiktoken_len(text):\n",
    "    token  = tokenizer.encode(\n",
    "        text,\n",
    "        disallowed_special=()\n",
    "    )\n",
    "    return len(token)\n",
    "token_counts = [tiktoken_len(doc.page_content) for doc in all_splits]\n",
    "print(sum(token_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID fe0721ee6440808fa601035d9a739752 in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID fe0721ee6440808fa601035d9a739752 in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID fe0721ee6440808fa601035d9a739752 in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Mon, 26 Jun 2023 17:47:10 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'plaksha-university-8pfafk', 'openai-processing-ms': '32087', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '778360', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '13.298s', 'x-request-id': 'fe0721ee6440808fa601035d9a739752', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7dd7454789056ef2-BOM', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n"
     ]
    }
   ],
   "source": [
    "#Embed and store the texts\n",
    "#Supplying a persist_directory will stoer the embeddings on disk\n",
    "persist_directory = \"db\"\n",
    "\n",
    "# create the open-source embedding function\n",
    "vectordb = Chroma.from_documents(documents=all_splits,embedding=OpenAIEmbeddings(),\n",
    "        persist_directory=persist_directory)\n",
    "\n",
    "#persist the db to disk\n",
    "vectordb.persist()\n",
    "vectordb = None\n",
    "\n",
    "vectordb = Chroma.from_documents(documents=all_splits,embedding=OpenAIEmbeddings(),\n",
    "        persist_directory=persist_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval = vectordb.as_retriever(search_kwargs={\"k\":2})\n",
    "#docs = retrieval.get_relevant_documents(\"Who is Rucha Joshi\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'query': 'Which professor should  meet to know more about DNA and why', 'result': ' You should meet Dr. Dhiraj Sinha to know more about DNA because he is a faculty member.', 'source_documents': [Document(page_content='faculty\\n      \\n    \\n    \\n      Dr. Dhiraj Sinha', metadata={'source': 'excel/database.xlsx'}), Document(page_content='faculty\\n      \\n    \\n    \\n      Dr. Dhiraj Sinha', metadata={'source': 'excel/database.xlsx'})]}\n",
      "Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "{context}\n",
      "\n",
      "Question: {question}\n",
      "Helpful Answer:\n",
      "120\n"
     ]
    }
   ],
   "source": [
    "with get_openai_callback() as cb:\n",
    "        qa_chain = RetrievalQA.from_chain_type(llm=OpenAI(), chain_type=\"map_rerank\", retriever=retrieval,\n",
    "                return_source_documents=True, verbose=True)\n",
    "        print(qa_chain(\"Which professor should  meet to know more about DNA and why\"))\n",
    "total_tokens = cb.total_tokens\n",
    "print(qa_chain.combine_documents_chain.llm_chain.prompt.template)\n",
    "print(total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: db/ (stored 0%)\n",
      "  adding: db/index/ (stored 0%)\n",
      "  adding: db/index/index_metadata_47f97897-52dc-4c38-a8a6-abc32c520d1b.pkl (deflated 11%)\n",
      "  adding: db/index/id_to_uuid_47f97897-52dc-4c38-a8a6-abc32c520d1b.pkl (deflated 37%)\n",
      "  adding: db/index/uuid_to_id_47f97897-52dc-4c38-a8a6-abc32c520d1b.pkl (deflated 41%)\n",
      "  adding: db/index/index_47f97897-52dc-4c38-a8a6-abc32c520d1b.bin (deflated 17%)\n",
      "  adding: db/chroma-embeddings.parquet (deflated 29%)\n",
      "  adding: db/chroma-collections.parquet (deflated 50%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r db.zip ./db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#To cleanup, you can delete the collection\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m vectordb\u001b[39m.\u001b[39;49mdelete_collection()\n\u001b[1;32m      3\u001b[0m vectordb\u001b[39m.\u001b[39mpersist()\n\u001b[1;32m      5\u001b[0m \u001b[39m#delete the directory\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain/vectorstores/chroma.py:328\u001b[0m, in \u001b[0;36mChroma.delete_collection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdelete_collection\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    327\u001b[0m     \u001b[39m\"\"\"Delete the collection.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 328\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_client\u001b[39m.\u001b[39;49mdelete_collection(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_collection\u001b[39m.\u001b[39;49mname)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/chromadb/api/local.py:230\u001b[0m, in \u001b[0;36mLocalAPI.delete_collection\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[39m@override\u001b[39m\n\u001b[1;32m    217\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdelete_collection\u001b[39m(\u001b[39mself\u001b[39m, name: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    218\u001b[0m     \u001b[39m\"\"\"Delete a collection with the given name.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[39m        name: The name of the collection to delete\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[39m        ```\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 230\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_db\u001b[39m.\u001b[39;49mdelete_collection(name)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/chromadb/db/duckdb.py:143\u001b[0m, in \u001b[0;36mDuckDB.delete_collection\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[39m@override\u001b[39m\n\u001b[1;32m    142\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdelete_collection\u001b[39m(\u001b[39mself\u001b[39m, name: \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> 143\u001b[0m     collection_uuid \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_collection_uuid_from_name(name)\n\u001b[1;32m    144\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_conn\u001b[39m.\u001b[39mexecute(\n\u001b[1;32m    145\u001b[0m         \u001b[39m\"\"\"DELETE FROM embeddings WHERE collection_uuid = ?\"\"\"\u001b[39;00m, [collection_uuid]\n\u001b[1;32m    146\u001b[0m     )\n\u001b[1;32m    148\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_delete_index(collection_uuid)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/chromadb/db/duckdb.py:83\u001b[0m, in \u001b[0;36mDuckDB.get_collection_uuid_from_name\u001b[0;34m(self, collection_name)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[39m@override\u001b[39m\n\u001b[1;32m     82\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_collection_uuid_from_name\u001b[39m(\u001b[39mself\u001b[39m, collection_name: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m UUID:\n\u001b[0;32m---> 83\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conn\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m     84\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mSELECT uuid FROM collections WHERE name = ?\u001b[39;49m\u001b[39m\"\u001b[39;49m, [collection_name]\n\u001b[1;32m     85\u001b[0m     )\u001b[39m.\u001b[39;49mfetchall()[\u001b[39m0\u001b[39;49m][\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#To cleanup, you can delete the collection\n",
    "vectordb.delete_collection()\n",
    "vectordb.persist()\n",
    "\n",
    "#delete the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf db/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Restarting the runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip db.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing langchain modules\n",
    "\n",
    "from langchain.document_loaders import UnstructuredExcelLoader\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain import OpenAI, VectorDBQA\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.text_splitter import TokenTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "from langchain.document_loaders import TextLoader\n",
    "import tiktoken\n",
    "from langchain.callbacks import get_openai_callback\n",
    "#importing the os\n",
    "\n",
    "from config import OPENAI_API_KEY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = \"db\"\n",
    "\n",
    "# create the open-source embedding function\n",
    "vectordb2 = Chroma(embedding_function=OpenAIEmbeddings(),\n",
    "        persist_directory=persist_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval = vectordb2.as_retriever(search_kwargs={\"k\":2})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'query': 'Which professor can I meet to learn C++ from and give information about him', 'result': ' You can meet Dr. Srikant Srinivasan to learn C++ from. He is a faculty member at the university.', 'source_documents': [Document(page_content='faculty\\n      \\n    \\n    \\n      Dr. Srikant Srinivasan', metadata={'source': 'excel/database.xlsx'}), Document(page_content='faculty\\n      \\n    \\n    \\n      Dr. Srikant Srinivasan', metadata={'source': 'excel/database.xlsx'}), Document(page_content='faculty\\n      \\n    \\n    \\n      Dr. Srikant Srinivasan', metadata={'source': 'excel/database.xlsx'}), Document(page_content='faculty\\n      \\n    \\n    \\n      Dr. Srikant Srinivasan', metadata={'source': 'excel/database.xlsx'})]}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
